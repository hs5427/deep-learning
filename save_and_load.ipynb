{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MYDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_in, num_hidden, num_output):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()   # [b, c, h, w] -> [b, c*h*w]\n",
    "        self.l1 = nn.Linear(num_in, num_hidden)\n",
    "        self.l2 = nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        z1 = self.l1(x)\n",
    "        a1 = F.relu(z1)\n",
    "        x = self.l2(a1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def learn(model, train_loader, val_loader, optimizer, loss_func, num_epochs, early_stopping=None):\n",
    "    # ログ\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    no_improve_count = 0\n",
    "    early_stop = 5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_val_loss = 0.0\n",
    "        running_val_acc = 0.0\n",
    "\n",
    "\n",
    "        for train_batch, data in enumerate(train_loader):\n",
    "\n",
    "            X, y = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            preds = model(X)\n",
    "            loss = F.cross_entropy(preds, y)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "\n",
    "            # パラメータ更新\n",
    "            optimizer.step()\n",
    "\n",
    "            # validation\n",
    "            with torch.no_grad():\n",
    "                for val_batch, data in enumerate(val_loader):\n",
    "                    X_val, y_val = data\n",
    "                    preds_val = model(X_val)\n",
    "                    val_loss = F.cross_entropy(preds_val, y_val)\n",
    "                    running_val_loss += val_loss.item()\n",
    "                    val_accuracy = torch.sum(torch.argmax(preds_val, dim=-1) == y_val) / y_val.shape[0]\n",
    "                    running_val_acc += val_accuracy.item()\n",
    "\n",
    "            train_losses.append(running_loss/(train_batch + 1))\n",
    "            val_losses.append(running_val_loss/(val_batch + 1))\n",
    "            val_accuracies.append(running_val_acc/(val_batch + 1))\n",
    "            print(f'epoch: {epoch+1}: train_loss:{train_losses[-1]}, val_loss:{running_val_loss/(val_batch + 1)}, val_acuraccy:{running_val_acc/(val_batch + 1)}')\n",
    "\n",
    "            if val_losses[-1] < best_val_loss:\n",
    "                best_val_loss = val_losses[-1]\n",
    "                no_improve_count = 0\n",
    "            else:\n",
    "                no_improve_count += 1\n",
    "\n",
    "            if no_improve_count and no_improve_count >= early_stop:\n",
    "                print('stopping early')\n",
    "                break\n",
    "\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: train_loss:2.346662998199463, val_loss:2.3322680791219077, val_acuraccy:0.10416666666666667\n",
      "epoch: 1: train_loss:2.323965311050415, val_loss:4.663248042265574, val_acuraccy:0.20833333333333334\n",
      "epoch: 1: train_loss:2.328332265218099, val_loss:6.990994652112325, val_acuraccy:0.3125\n",
      "epoch: 1: train_loss:2.331631064414978, val_loss:9.316917717456818, val_acuraccy:0.4088541666666667\n",
      "epoch: 1: train_loss:2.3188130378723146, val_loss:11.644083460172018, val_acuraccy:0.5130208333333334\n",
      "epoch: 1: train_loss:2.31836199760437, val_loss:13.970057229200998, val_acuraccy:0.6171875\n",
      "stopping early\n",
      "epoch: 2: train_loss:2.3314902782440186, val_loss:2.322183847427368, val_acuraccy:0.10416666666666667\n",
      "epoch: 2: train_loss:2.3122187852859497, val_loss:4.644422094027202, val_acuraccy:0.20833333333333334\n",
      "epoch: 2: train_loss:2.3170200188954673, val_loss:6.966571748256683, val_acuraccy:0.3125\n",
      "epoch: 2: train_loss:2.301735520362854, val_loss:9.292587459087372, val_acuraccy:0.4088541666666667\n",
      "epoch: 2: train_loss:2.3119726181030273, val_loss:11.614847203095755, val_acuraccy:0.5052083333333334\n",
      "epoch: 2: train_loss:2.309801618258158, val_loss:13.936556239922842, val_acuraccy:0.6015625\n",
      "stopping early\n",
      "epoch: 3: train_loss:2.278630495071411, val_loss:2.323681890964508, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 4: train_loss:2.3275434970855713, val_loss:2.322841703891754, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 5: train_loss:2.2969489097595215, val_loss:2.324067215124766, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 6: train_loss:2.3374109268188477, val_loss:2.3221817215283713, val_acuraccy:0.08072916666666667\n",
      "epoch: 6: train_loss:2.3144220113754272, val_loss:4.646516541639964, val_acuraccy:0.16145833333333334\n",
      "epoch: 6: train_loss:2.316940943400065, val_loss:6.969770471254985, val_acuraccy:0.2421875\n",
      "epoch: 6: train_loss:2.3195096254348755, val_loss:9.291530787944794, val_acuraccy:0.3229166666666667\n",
      "epoch: 6: train_loss:2.316681385040283, val_loss:11.612116992473602, val_acuraccy:0.4036458333333333\n",
      "epoch: 6: train_loss:2.314824938774109, val_loss:13.931773801644644, val_acuraccy:0.484375\n",
      "stopping early\n",
      "epoch: 7: train_loss:2.3068737983703613, val_loss:2.3204819162686667, val_acuraccy:0.08072916666666667\n",
      "epoch: 7: train_loss:2.3026076555252075, val_loss:4.641151428222656, val_acuraccy:0.16145833333333334\n",
      "epoch: 7: train_loss:2.3004511992136636, val_loss:6.961981495221456, val_acuraccy:0.2421875\n",
      "epoch: 7: train_loss:2.2981045246124268, val_loss:9.284348666667938, val_acuraccy:0.3229166666666667\n",
      "epoch: 7: train_loss:2.295072650909424, val_loss:11.608578940232595, val_acuraccy:0.4036458333333333\n",
      "epoch: 7: train_loss:2.2974379857381186, val_loss:13.931505382061005, val_acuraccy:0.484375\n",
      "stopping early\n",
      "epoch: 8: train_loss:2.281217575073242, val_loss:2.323453366756439, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 9: train_loss:2.291964054107666, val_loss:2.323154071966807, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 10: train_loss:2.3192567825317383, val_loss:2.3227059046427407, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 11: train_loss:2.2736456394195557, val_loss:2.3238263924916587, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 12: train_loss:2.316148042678833, val_loss:2.321634570757548, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 13: train_loss:2.323068857192993, val_loss:2.321471869945526, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 14: train_loss:2.3158113956451416, val_loss:2.321064829826355, val_acuraccy:0.08072916666666667\n",
      "stopping early\n",
      "epoch: 15: train_loss:2.315946578979492, val_loss:2.3201457858085632, val_acuraccy:0.08072916666666667\n",
      "epoch: 15: train_loss:2.324891686439514, val_loss:4.638193567593892, val_acuraccy:0.16145833333333334\n",
      "epoch: 15: train_loss:2.3217879136403403, val_loss:6.955993910630544, val_acuraccy:0.2421875\n",
      "epoch: 15: train_loss:2.3161937594413757, val_loss:9.273384610811869, val_acuraccy:0.3229166666666667\n",
      "epoch: 15: train_loss:2.3130289554595946, val_loss:11.590763727823893, val_acuraccy:0.4036458333333333\n",
      "epoch: 15: train_loss:2.311664899190267, val_loss:13.90794942776362, val_acuraccy:0.484375\n",
      "stopping early\n",
      "epoch: 16: train_loss:2.286052703857422, val_loss:2.317846973737081, val_acuraccy:0.08072916666666667\n",
      "epoch: 16: train_loss:2.31450355052948, val_loss:4.633401552836101, val_acuraccy:0.16145833333333334\n",
      "epoch: 16: train_loss:2.3097668488820395, val_loss:6.949347953001658, val_acuraccy:0.2421875\n",
      "epoch: 16: train_loss:2.306563973426819, val_loss:9.264642556508383, val_acuraccy:0.3229166666666667\n",
      "epoch: 16: train_loss:2.3027220726013184, val_loss:11.580120225747427, val_acuraccy:0.4036458333333333\n",
      "epoch: 16: train_loss:2.302462339401245, val_loss:13.89618992805481, val_acuraccy:0.4973958333333333\n",
      "stopping early\n",
      "epoch: 17: train_loss:2.306459426879883, val_loss:2.31559290488561, val_acuraccy:0.09375\n",
      "epoch: 17: train_loss:2.31141459941864, val_loss:4.630561272303264, val_acuraccy:0.1875\n",
      "epoch: 17: train_loss:2.3091331322987876, val_loss:6.944902698198955, val_acuraccy:0.28125\n",
      "epoch: 17: train_loss:2.314211130142212, val_loss:9.258420606454214, val_acuraccy:0.3697916666666667\n",
      "epoch: 17: train_loss:2.3126039028167726, val_loss:11.572761416435242, val_acuraccy:0.4557291666666667\n",
      "epoch: 17: train_loss:2.3107059001922607, val_loss:13.886759042739868, val_acuraccy:0.5416666666666666\n",
      "stopping early\n",
      "epoch: 18: train_loss:2.315044403076172, val_loss:2.3127940893173218, val_acuraccy:0.08072916666666667\n",
      "epoch: 18: train_loss:2.3093186616897583, val_loss:4.626066088676453, val_acuraccy:0.16666666666666666\n",
      "epoch: 18: train_loss:2.313051144282023, val_loss:6.939391533533732, val_acuraccy:0.2526041666666667\n",
      "epoch: 18: train_loss:2.31124746799469, val_loss:9.252767860889435, val_acuraccy:0.3385416666666667\n",
      "epoch: 18: train_loss:2.3091883659362793, val_loss:11.565764168898264, val_acuraccy:0.4192708333333333\n",
      "epoch: 18: train_loss:2.3093949953715005, val_loss:13.877910415331522, val_acuraccy:0.4947916666666667\n",
      "stopping early\n",
      "epoch: 19: train_loss:2.3171865940093994, val_loss:2.3113921682039895, val_acuraccy:0.0859375\n",
      "epoch: 19: train_loss:2.3181850910186768, val_loss:4.62185271581014, val_acuraccy:0.16666666666666666\n",
      "epoch: 19: train_loss:2.3114009698232016, val_loss:6.932695249716441, val_acuraccy:0.2630208333333333\n",
      "epoch: 19: train_loss:2.3113401532173157, val_loss:9.243761539459229, val_acuraccy:0.34375\n",
      "epoch: 19: train_loss:2.3096595287322996, val_loss:11.55510793129603, val_acuraccy:0.4244791666666667\n",
      "epoch: 19: train_loss:2.311089793841044, val_loss:13.865801016489664, val_acuraccy:0.5052083333333334\n",
      "stopping early\n",
      "epoch: 20: train_loss:2.298551559448242, val_loss:2.3102492690086365, val_acuraccy:0.08072916666666667\n",
      "epoch: 20: train_loss:2.303413152694702, val_loss:4.621372759342194, val_acuraccy:0.16666666666666666\n",
      "epoch: 20: train_loss:2.3058454990386963, val_loss:6.93160343170166, val_acuraccy:0.24739583333333334\n",
      "epoch: 20: train_loss:2.299879550933838, val_loss:9.242919743061066, val_acuraccy:0.328125\n",
      "epoch: 20: train_loss:2.2998427391052245, val_loss:11.55433883269628, val_acuraccy:0.4140625\n",
      "epoch: 20: train_loss:2.299811522165934, val_loss:13.865692993005117, val_acuraccy:0.5\n",
      "stopping early\n",
      "epoch: 21: train_loss:2.30896258354187, val_loss:2.3117977182070413, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 22: train_loss:2.3124241828918457, val_loss:2.3100804487864175, val_acuraccy:0.09375\n",
      "epoch: 22: train_loss:2.3024563789367676, val_loss:4.62153164545695, val_acuraccy:0.1796875\n",
      "epoch: 22: train_loss:2.2986409664154053, val_loss:6.933542152245839, val_acuraccy:0.2734375\n",
      "epoch: 22: train_loss:2.3026838898658752, val_loss:9.24494089682897, val_acuraccy:0.3671875\n",
      "epoch: 22: train_loss:2.297775936126709, val_loss:11.556991398334503, val_acuraccy:0.4609375\n",
      "epoch: 22: train_loss:2.294972856839498, val_loss:13.870368401209513, val_acuraccy:0.546875\n",
      "stopping early\n",
      "epoch: 23: train_loss:2.2919986248016357, val_loss:2.313954512278239, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 24: train_loss:2.2997817993164062, val_loss:2.3133765856424966, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 25: train_loss:2.3028690814971924, val_loss:2.313464423020681, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 26: train_loss:2.3197975158691406, val_loss:2.3128729859987893, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 27: train_loss:2.3083176612854004, val_loss:2.31296177705129, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 28: train_loss:2.316178798675537, val_loss:2.313539505004883, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 29: train_loss:2.2817859649658203, val_loss:2.3149001797040305, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 30: train_loss:2.2874338626861572, val_loss:2.3156057000160217, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 31: train_loss:2.294109582901001, val_loss:2.316200931866964, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 32: train_loss:2.3081870079040527, val_loss:2.3159651358922324, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 33: train_loss:2.302942991256714, val_loss:2.316840092341105, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 34: train_loss:2.2798421382904053, val_loss:2.3188305298487344, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 35: train_loss:2.2980833053588867, val_loss:2.319346606731415, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 36: train_loss:2.3065919876098633, val_loss:2.3190352519353232, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 37: train_loss:2.2752132415771484, val_loss:2.321540057659149, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 38: train_loss:2.313288688659668, val_loss:2.32246071100235, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 39: train_loss:2.270270347595215, val_loss:2.323842982451121, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 40: train_loss:2.3019251823425293, val_loss:2.3241120179494223, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 41: train_loss:2.249371290206909, val_loss:2.3266499439875283, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 42: train_loss:2.3350350856781006, val_loss:2.3257389068603516, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 43: train_loss:2.352268695831299, val_loss:2.3232957124710083, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 44: train_loss:2.2861006259918213, val_loss:2.324405570824941, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 45: train_loss:2.2830722332000732, val_loss:2.3248904943466187, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 46: train_loss:2.3058927059173584, val_loss:2.3239535291989646, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 47: train_loss:2.3171539306640625, val_loss:2.3221529920895896, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 48: train_loss:2.320539712905884, val_loss:2.3216673533121743, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 49: train_loss:2.3463549613952637, val_loss:2.3196778297424316, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 50: train_loss:2.2831132411956787, val_loss:2.320358673731486, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 51: train_loss:2.2952635288238525, val_loss:2.320990482966105, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 52: train_loss:2.2506656646728516, val_loss:2.3231077194213867, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 53: train_loss:2.3137283325195312, val_loss:2.32199364900589, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 54: train_loss:2.332303762435913, val_loss:2.3207105795542398, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 55: train_loss:2.3097856044769287, val_loss:2.3206267754236856, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 56: train_loss:2.339519500732422, val_loss:2.319293439388275, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 57: train_loss:2.3256824016571045, val_loss:2.319193661212921, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 58: train_loss:2.2838664054870605, val_loss:2.319870114326477, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 59: train_loss:2.2793209552764893, val_loss:2.320169428984324, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 60: train_loss:2.3212192058563232, val_loss:2.3193673888842263, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 61: train_loss:2.2937424182891846, val_loss:2.3200804591178894, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 62: train_loss:2.3001046180725098, val_loss:2.3204333583513894, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 63: train_loss:2.306274175643921, val_loss:2.3189955353736877, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 64: train_loss:2.2764430046081543, val_loss:2.321003715197245, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 65: train_loss:2.308607339859009, val_loss:2.3204526702562966, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 66: train_loss:2.284167766571045, val_loss:2.3209550182024636, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 67: train_loss:2.305095911026001, val_loss:2.3201786875724792, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 68: train_loss:2.3532896041870117, val_loss:2.3172102570533752, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 69: train_loss:2.307201862335205, val_loss:2.317110459009806, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 70: train_loss:2.287003993988037, val_loss:2.3176241914431253, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 71: train_loss:2.303067207336426, val_loss:2.317618648211161, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 72: train_loss:2.2950656414031982, val_loss:2.317918380101522, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 73: train_loss:2.3125545978546143, val_loss:2.317164957523346, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 74: train_loss:2.2825376987457275, val_loss:2.317690392335256, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 75: train_loss:2.3139472007751465, val_loss:2.3170450727144876, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 76: train_loss:2.308043956756592, val_loss:2.317073345184326, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 77: train_loss:2.330329418182373, val_loss:2.315568447113037, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 78: train_loss:2.2982029914855957, val_loss:2.315918783346812, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 79: train_loss:2.3221049308776855, val_loss:2.315680980682373, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 80: train_loss:2.3073174953460693, val_loss:2.3153329888979592, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 81: train_loss:2.2903804779052734, val_loss:2.3151793479919434, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 82: train_loss:2.3027400970458984, val_loss:2.3157039483388266, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 83: train_loss:2.308971881866455, val_loss:2.313551127910614, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 84: train_loss:2.300222873687744, val_loss:2.3136173685391745, val_acuraccy:0.09375\n",
      "stopping early\n",
      "epoch: 85: train_loss:2.3123526573181152, val_loss:2.312775949637095, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 86: train_loss:2.3156204223632812, val_loss:2.312624931335449, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 87: train_loss:2.311800479888916, val_loss:2.313929796218872, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 88: train_loss:2.295748233795166, val_loss:2.3143545587857566, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 89: train_loss:2.280590295791626, val_loss:2.3156813184420266, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 90: train_loss:2.307141065597534, val_loss:2.3153268694877625, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 91: train_loss:2.305325984954834, val_loss:2.315182328224182, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 92: train_loss:2.3135986328125, val_loss:2.315575897693634, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 93: train_loss:2.3154382705688477, val_loss:2.314622978369395, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 94: train_loss:2.2765684127807617, val_loss:2.316913425922394, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 95: train_loss:2.336580276489258, val_loss:2.3147964080174765, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 96: train_loss:2.295614719390869, val_loss:2.3146117528279624, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 97: train_loss:2.311596393585205, val_loss:2.313270886739095, val_acuraccy:0.13541666666666666\n",
      "stopping early\n",
      "epoch: 98: train_loss:2.313523054122925, val_loss:2.31290739774704, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 99: train_loss:2.315506935119629, val_loss:2.3122859398523965, val_acuraccy:0.10416666666666667\n",
      "stopping early\n",
      "epoch: 100: train_loss:2.311896800994873, val_loss:2.3119307359059653, val_acuraccy:0.10416666666666667\n",
      "stopping early\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.346662998199463,\n",
       "  2.323965311050415,\n",
       "  2.328332265218099,\n",
       "  2.331631064414978,\n",
       "  2.3188130378723146,\n",
       "  2.31836199760437,\n",
       "  2.3314902782440186,\n",
       "  2.3122187852859497,\n",
       "  2.3170200188954673,\n",
       "  2.301735520362854,\n",
       "  2.3119726181030273,\n",
       "  2.309801618258158,\n",
       "  2.278630495071411,\n",
       "  2.3275434970855713,\n",
       "  2.2969489097595215,\n",
       "  2.3374109268188477,\n",
       "  2.3144220113754272,\n",
       "  2.316940943400065,\n",
       "  2.3195096254348755,\n",
       "  2.316681385040283,\n",
       "  2.314824938774109,\n",
       "  2.3068737983703613,\n",
       "  2.3026076555252075,\n",
       "  2.3004511992136636,\n",
       "  2.2981045246124268,\n",
       "  2.295072650909424,\n",
       "  2.2974379857381186,\n",
       "  2.281217575073242,\n",
       "  2.291964054107666,\n",
       "  2.3192567825317383,\n",
       "  2.2736456394195557,\n",
       "  2.316148042678833,\n",
       "  2.323068857192993,\n",
       "  2.3158113956451416,\n",
       "  2.315946578979492,\n",
       "  2.324891686439514,\n",
       "  2.3217879136403403,\n",
       "  2.3161937594413757,\n",
       "  2.3130289554595946,\n",
       "  2.311664899190267,\n",
       "  2.286052703857422,\n",
       "  2.31450355052948,\n",
       "  2.3097668488820395,\n",
       "  2.306563973426819,\n",
       "  2.3027220726013184,\n",
       "  2.302462339401245,\n",
       "  2.306459426879883,\n",
       "  2.31141459941864,\n",
       "  2.3091331322987876,\n",
       "  2.314211130142212,\n",
       "  2.3126039028167726,\n",
       "  2.3107059001922607,\n",
       "  2.315044403076172,\n",
       "  2.3093186616897583,\n",
       "  2.313051144282023,\n",
       "  2.31124746799469,\n",
       "  2.3091883659362793,\n",
       "  2.3093949953715005,\n",
       "  2.3171865940093994,\n",
       "  2.3181850910186768,\n",
       "  2.3114009698232016,\n",
       "  2.3113401532173157,\n",
       "  2.3096595287322996,\n",
       "  2.311089793841044,\n",
       "  2.298551559448242,\n",
       "  2.303413152694702,\n",
       "  2.3058454990386963,\n",
       "  2.299879550933838,\n",
       "  2.2998427391052245,\n",
       "  2.299811522165934,\n",
       "  2.30896258354187,\n",
       "  2.3124241828918457,\n",
       "  2.3024563789367676,\n",
       "  2.2986409664154053,\n",
       "  2.3026838898658752,\n",
       "  2.297775936126709,\n",
       "  2.294972856839498,\n",
       "  2.2919986248016357,\n",
       "  2.2997817993164062,\n",
       "  2.3028690814971924,\n",
       "  2.3197975158691406,\n",
       "  2.3083176612854004,\n",
       "  2.316178798675537,\n",
       "  2.2817859649658203,\n",
       "  2.2874338626861572,\n",
       "  2.294109582901001,\n",
       "  2.3081870079040527,\n",
       "  2.302942991256714,\n",
       "  2.2798421382904053,\n",
       "  2.2980833053588867,\n",
       "  2.3065919876098633,\n",
       "  2.2752132415771484,\n",
       "  2.313288688659668,\n",
       "  2.270270347595215,\n",
       "  2.3019251823425293,\n",
       "  2.249371290206909,\n",
       "  2.3350350856781006,\n",
       "  2.352268695831299,\n",
       "  2.2861006259918213,\n",
       "  2.2830722332000732,\n",
       "  2.3058927059173584,\n",
       "  2.3171539306640625,\n",
       "  2.320539712905884,\n",
       "  2.3463549613952637,\n",
       "  2.2831132411956787,\n",
       "  2.2952635288238525,\n",
       "  2.2506656646728516,\n",
       "  2.3137283325195312,\n",
       "  2.332303762435913,\n",
       "  2.3097856044769287,\n",
       "  2.339519500732422,\n",
       "  2.3256824016571045,\n",
       "  2.2838664054870605,\n",
       "  2.2793209552764893,\n",
       "  2.3212192058563232,\n",
       "  2.2937424182891846,\n",
       "  2.3001046180725098,\n",
       "  2.306274175643921,\n",
       "  2.2764430046081543,\n",
       "  2.308607339859009,\n",
       "  2.284167766571045,\n",
       "  2.305095911026001,\n",
       "  2.3532896041870117,\n",
       "  2.307201862335205,\n",
       "  2.287003993988037,\n",
       "  2.303067207336426,\n",
       "  2.2950656414031982,\n",
       "  2.3125545978546143,\n",
       "  2.2825376987457275,\n",
       "  2.3139472007751465,\n",
       "  2.308043956756592,\n",
       "  2.330329418182373,\n",
       "  2.2982029914855957,\n",
       "  2.3221049308776855,\n",
       "  2.3073174953460693,\n",
       "  2.2903804779052734,\n",
       "  2.3027400970458984,\n",
       "  2.308971881866455,\n",
       "  2.300222873687744,\n",
       "  2.3123526573181152,\n",
       "  2.3156204223632812,\n",
       "  2.311800479888916,\n",
       "  2.295748233795166,\n",
       "  2.280590295791626,\n",
       "  2.307141065597534,\n",
       "  2.305325984954834,\n",
       "  2.3135986328125,\n",
       "  2.3154382705688477,\n",
       "  2.2765684127807617,\n",
       "  2.336580276489258,\n",
       "  2.295614719390869,\n",
       "  2.311596393585205,\n",
       "  2.313523054122925,\n",
       "  2.315506935119629,\n",
       "  2.311896800994873],\n",
       " [2.3322680791219077,\n",
       "  4.663248042265574,\n",
       "  6.990994652112325,\n",
       "  9.316917717456818,\n",
       "  11.644083460172018,\n",
       "  13.970057229200998,\n",
       "  2.322183847427368,\n",
       "  4.644422094027202,\n",
       "  6.966571748256683,\n",
       "  9.292587459087372,\n",
       "  11.614847203095755,\n",
       "  13.936556239922842,\n",
       "  2.323681890964508,\n",
       "  2.322841703891754,\n",
       "  2.324067215124766,\n",
       "  2.3221817215283713,\n",
       "  4.646516541639964,\n",
       "  6.969770471254985,\n",
       "  9.291530787944794,\n",
       "  11.612116992473602,\n",
       "  13.931773801644644,\n",
       "  2.3204819162686667,\n",
       "  4.641151428222656,\n",
       "  6.961981495221456,\n",
       "  9.284348666667938,\n",
       "  11.608578940232595,\n",
       "  13.931505382061005,\n",
       "  2.323453366756439,\n",
       "  2.323154071966807,\n",
       "  2.3227059046427407,\n",
       "  2.3238263924916587,\n",
       "  2.321634570757548,\n",
       "  2.321471869945526,\n",
       "  2.321064829826355,\n",
       "  2.3201457858085632,\n",
       "  4.638193567593892,\n",
       "  6.955993910630544,\n",
       "  9.273384610811869,\n",
       "  11.590763727823893,\n",
       "  13.90794942776362,\n",
       "  2.317846973737081,\n",
       "  4.633401552836101,\n",
       "  6.949347953001658,\n",
       "  9.264642556508383,\n",
       "  11.580120225747427,\n",
       "  13.89618992805481,\n",
       "  2.31559290488561,\n",
       "  4.630561272303264,\n",
       "  6.944902698198955,\n",
       "  9.258420606454214,\n",
       "  11.572761416435242,\n",
       "  13.886759042739868,\n",
       "  2.3127940893173218,\n",
       "  4.626066088676453,\n",
       "  6.939391533533732,\n",
       "  9.252767860889435,\n",
       "  11.565764168898264,\n",
       "  13.877910415331522,\n",
       "  2.3113921682039895,\n",
       "  4.62185271581014,\n",
       "  6.932695249716441,\n",
       "  9.243761539459229,\n",
       "  11.55510793129603,\n",
       "  13.865801016489664,\n",
       "  2.3102492690086365,\n",
       "  4.621372759342194,\n",
       "  6.93160343170166,\n",
       "  9.242919743061066,\n",
       "  11.55433883269628,\n",
       "  13.865692993005117,\n",
       "  2.3117977182070413,\n",
       "  2.3100804487864175,\n",
       "  4.62153164545695,\n",
       "  6.933542152245839,\n",
       "  9.24494089682897,\n",
       "  11.556991398334503,\n",
       "  13.870368401209513,\n",
       "  2.313954512278239,\n",
       "  2.3133765856424966,\n",
       "  2.313464423020681,\n",
       "  2.3128729859987893,\n",
       "  2.31296177705129,\n",
       "  2.313539505004883,\n",
       "  2.3149001797040305,\n",
       "  2.3156057000160217,\n",
       "  2.316200931866964,\n",
       "  2.3159651358922324,\n",
       "  2.316840092341105,\n",
       "  2.3188305298487344,\n",
       "  2.319346606731415,\n",
       "  2.3190352519353232,\n",
       "  2.321540057659149,\n",
       "  2.32246071100235,\n",
       "  2.323842982451121,\n",
       "  2.3241120179494223,\n",
       "  2.3266499439875283,\n",
       "  2.3257389068603516,\n",
       "  2.3232957124710083,\n",
       "  2.324405570824941,\n",
       "  2.3248904943466187,\n",
       "  2.3239535291989646,\n",
       "  2.3221529920895896,\n",
       "  2.3216673533121743,\n",
       "  2.3196778297424316,\n",
       "  2.320358673731486,\n",
       "  2.320990482966105,\n",
       "  2.3231077194213867,\n",
       "  2.32199364900589,\n",
       "  2.3207105795542398,\n",
       "  2.3206267754236856,\n",
       "  2.319293439388275,\n",
       "  2.319193661212921,\n",
       "  2.319870114326477,\n",
       "  2.320169428984324,\n",
       "  2.3193673888842263,\n",
       "  2.3200804591178894,\n",
       "  2.3204333583513894,\n",
       "  2.3189955353736877,\n",
       "  2.321003715197245,\n",
       "  2.3204526702562966,\n",
       "  2.3209550182024636,\n",
       "  2.3201786875724792,\n",
       "  2.3172102570533752,\n",
       "  2.317110459009806,\n",
       "  2.3176241914431253,\n",
       "  2.317618648211161,\n",
       "  2.317918380101522,\n",
       "  2.317164957523346,\n",
       "  2.317690392335256,\n",
       "  2.3170450727144876,\n",
       "  2.317073345184326,\n",
       "  2.315568447113037,\n",
       "  2.315918783346812,\n",
       "  2.315680980682373,\n",
       "  2.3153329888979592,\n",
       "  2.3151793479919434,\n",
       "  2.3157039483388266,\n",
       "  2.313551127910614,\n",
       "  2.3136173685391745,\n",
       "  2.312775949637095,\n",
       "  2.312624931335449,\n",
       "  2.313929796218872,\n",
       "  2.3143545587857566,\n",
       "  2.3156813184420266,\n",
       "  2.3153268694877625,\n",
       "  2.315182328224182,\n",
       "  2.315575897693634,\n",
       "  2.314622978369395,\n",
       "  2.316913425922394,\n",
       "  2.3147964080174765,\n",
       "  2.3146117528279624,\n",
       "  2.313270886739095,\n",
       "  2.31290739774704,\n",
       "  2.3122859398523965,\n",
       "  2.3119307359059653],\n",
       " [0.10416666666666667,\n",
       "  0.20833333333333334,\n",
       "  0.3125,\n",
       "  0.4088541666666667,\n",
       "  0.5130208333333334,\n",
       "  0.6171875,\n",
       "  0.10416666666666667,\n",
       "  0.20833333333333334,\n",
       "  0.3125,\n",
       "  0.4088541666666667,\n",
       "  0.5052083333333334,\n",
       "  0.6015625,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.16145833333333334,\n",
       "  0.2421875,\n",
       "  0.3229166666666667,\n",
       "  0.4036458333333333,\n",
       "  0.484375,\n",
       "  0.08072916666666667,\n",
       "  0.16145833333333334,\n",
       "  0.2421875,\n",
       "  0.3229166666666667,\n",
       "  0.4036458333333333,\n",
       "  0.484375,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.08072916666666667,\n",
       "  0.16145833333333334,\n",
       "  0.2421875,\n",
       "  0.3229166666666667,\n",
       "  0.4036458333333333,\n",
       "  0.484375,\n",
       "  0.08072916666666667,\n",
       "  0.16145833333333334,\n",
       "  0.2421875,\n",
       "  0.3229166666666667,\n",
       "  0.4036458333333333,\n",
       "  0.4973958333333333,\n",
       "  0.09375,\n",
       "  0.1875,\n",
       "  0.28125,\n",
       "  0.3697916666666667,\n",
       "  0.4557291666666667,\n",
       "  0.5416666666666666,\n",
       "  0.08072916666666667,\n",
       "  0.16666666666666666,\n",
       "  0.2526041666666667,\n",
       "  0.3385416666666667,\n",
       "  0.4192708333333333,\n",
       "  0.4947916666666667,\n",
       "  0.0859375,\n",
       "  0.16666666666666666,\n",
       "  0.2630208333333333,\n",
       "  0.34375,\n",
       "  0.4244791666666667,\n",
       "  0.5052083333333334,\n",
       "  0.08072916666666667,\n",
       "  0.16666666666666666,\n",
       "  0.24739583333333334,\n",
       "  0.328125,\n",
       "  0.4140625,\n",
       "  0.5,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.1796875,\n",
       "  0.2734375,\n",
       "  0.3671875,\n",
       "  0.4609375,\n",
       "  0.546875,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.09375,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.13541666666666666,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667,\n",
       "  0.10416666666666667])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データロード\n",
    "dataset = datasets.load_digits()\n",
    "target = dataset['target']\n",
    "images = dataset['images']\n",
    "images = images / (255. / 16.)   # 0-16 -> 0-255\n",
    "images = images.astype(np.uint8)\n",
    "# 学習データと検証データに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# DatasetとDataLoaderの作成\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "batch_size = 32\n",
    "train_mydataset = MYDataset(X_train, y_train, transform=transform)\n",
    "val_mydataset = MYDataset(X_val, y_val, transform=transform)\n",
    "train_myloader = DataLoader(train_mydataset, batch_size=batch_size, shuffle=True)\n",
    "val_myloader = DataLoader(val_mydataset, batch_size=batch_size, shuffle=False)\n",
    "early_stopping = 5\n",
    "\n",
    "## Refactoring後の学習ループ\n",
    "epochs = 100\n",
    "learning_rate = 0.03\n",
    "model = MLP(64, 30, 10)\n",
    "opt = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "learn(model, train_myloader, val_myloader, opt, F.cross_entropy, epochs, early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbcb1696940>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルオブジェクトの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.save(model, 'sample_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルパラメータの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_model = MLP(64, 30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0506,  0.1056, -0.0886,  ..., -0.0413,  0.0196,  0.0088],\n",
       "        [-0.0862, -0.0118,  0.1015,  ...,  0.1169, -0.0654, -0.0286],\n",
       "        [ 0.0755, -0.0601, -0.0569,  ...,  0.0268, -0.0300, -0.0717],\n",
       "        ...,\n",
       "        [ 0.0723,  0.1170,  0.0233,  ...,  0.1085,  0.0122,  0.1290],\n",
       "        [-0.0191, -0.1131, -0.0548,  ...,  0.0099, -0.1253, -0.0532],\n",
       "        [ 0.0483,  0.0399, -0.0713,  ...,  0.0327,  0.1106,  0.0655]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.l1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'sample_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_model.load_state_dict(torch.load('sample_model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
